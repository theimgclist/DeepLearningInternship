![picture](https://media.giphy.com/media/rUtDCuiPlFE52/giphy-downsized-large.gif)
<p align="center"><a href="https://www.meetup.com/opensourceblr/events/248254677/">Pic Credit</a></p>
Using computeres and technology to mimic human-like behaviour and perform human activities(though not at the same level of efficiency and accuracy) are in place from many past years. But almost all of them got revamped into a whole new version - with improved accuracy, speed and performance. The credit for that goes to Machine Learning. And when we talk about Machine Learning, there is one thing about it that has become ubiquitous - Neural Networks. Neural networks are everywhere. Besides tasks like object detection, face recognition, machine translation neural networks are also being used for other interesting tasks like restoring colors in black and white photos, photo description, playing games and even beating humans, self driving cars etc.  
<br>
<br>
There is so much craze and hype around neural networks. What makes neural networks so good? And how do they perform better than the traditional machine learning algorithms? Though there could be several answers for these questions, they can be summarized using - the availability of large amount of data and the architecture of the neural networks. We quite often hear things like "The model you build and train is as good as the data you feed into it", "More data the better" . This is not only true incase of neural networks but also a requirement(in most cases). The other thing that makes neural networks perform really good is the architecture. In the rest of the article, I will try and explain few components of a Convolutional Neural Network, which is a class of feed forward neural networks.
<br>
<br>
>What is Convolution?
<br>
<br>
If you have used any image editor or app before, you must have used convolutions. Any decent image app will give you options like blurring the image, changing it's contrast, sharpening etc. Convolution is nothing but taking an image, applying some transformation on it to produce a some what variant version of the image. How does this help neural networks? To know the answer, we should know what *kernels/features* are!
<p align="center"><img src="https://ujwlkarn.files.wordpress.com/2016/08/giphy.gif?w=480&zoom=2>"/></p>
<p align="center"><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/">Pic Credit</a></p>
While reading any part of this article, you would have fixed your eyes on one/few words and then keep glancing over the words that followed. In reading terms, each such glance is called a fixation. Even for a human eye, it's not posssible to grasp or understand the entire content in one go. When it comes to neural networks, we have something similar called kernels or filters. If we have an input image, computer stores it as a 2D matrix, each pixel having some numerical value. Kernel is just another matrix(much smaller when compared to the input matrix) that starts at top-left corner of the matrix and passes through till it reaches the bottom-right corner. The above picture shows an example of how 2 filters are applied on an image. <br><br>
In convolution, each kernel matrix is passed through the input image matrix and the sum of element wise multiplication is calculated and stored. It then takes a stride and moves to the next region of the image. Once the kernel is done traversing through the entire image, an activation function is applied on the stored sums of each kernel glance. This gives us the feature map. So for an input image, there can be n number of kernels. Each of the kernel will result in a separate feature map. The set of all the feature maps from one layer will act as input for the next layer. If a 3X3 kernel is applied on a 5X5 input image, it gives a 2X2 feature map when the stride is 1. Each kernel will extract a specific feature from the image. The kernels in the initial layers will extract basic shapes like edges. The layers that follow build on top of the previously extracted features to extract more abstract features.<br><br>
![picture](https://mlblr.com/images/4-2ConvolutionSmall.gif)
<br>
<p align="center"> Example of a filter convolution </p><br>
This is repeated for every image/sample in the training dataset and for as many number of epochs that the model is designed to run. One epoch is iterating through all the samples in a training set for once. If the model runs for 3 epochs, then it would have seen every sample in the training set thrice.<br><br>
In convolution, we are applying an activation function on the output of each kernel. Can't we do without it? The main purpose of having an activation function is to introduce non-linearity into the network. Since neural networks are mainly used to mimic some of the human behavior and activities, they are often non linear in nature. To put it simply, this helps in capturing more detailed features without which we can only extract linear features. There are many activation functions that are available. Sigmoid, Relu, tanh are some of the most widely used activation functions. Among the three, Relu is considered to be the activation function that works pretty well. It is a simple function that takes in a value and returns 0 if it's negative and the same value otherwise.