{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AVINASH_BATCH_1_ASSIGNMENT4B.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1_1kwmwgL7g94jI6BEtcgm-D2_AFk0zxK",
          "timestamp": 1519101209834
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sUifhoSDkYct",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Avinash Kappa - Assignment 4b \n",
        "\n",
        "###Trials and observations:\n",
        "\n",
        "**In my first submission last week, I got test accuracy of 85.84%.  **   \n",
        "\n",
        "After having tried a few things, what worked to get >85% accuracy was reducing the batch size to 64 and increasing filters to 24.  \n",
        "###To reach 87% accuracy, these are the things I tried :  \n",
        "\n",
        "I tried for different dropouts like 0.5 and 0.3 which didnt give better results so I left the dropout as 0.2.  \n",
        "\n",
        "I trained the same model with 85.84% accuracy again to see if it might give any better results. It didn't.  \n",
        "\n",
        "I decreased the batch size to 32 and increased filters to 32. Each epoch was taking too long for Colab and the runtime was dying intermittently.   \n",
        "\n",
        "I then used data augmentation along with two convolution layers that are added before the 1st convolution layer.  \n",
        "\n",
        "These 2 convolution layers are of filter dimensions 1 X 7 and 7 X 1.  \n",
        "\n",
        "In the last trial on Colab, the runtime stopped when the training was at epoch 13. Validation accuracy at this point was 77.7%  \n",
        "\n",
        "I took the saved weights and resumed the training with epochs = 38.  \n",
        "\n",
        "**At epoch 25/38, which is the 37th epoch overall out of 50, the validation accuracy reached 87.4%**    \n",
        "\n",
        "**The training ended with the best validation accuracy of 88.02.  **\n",
        "\n",
        "Using the trained model as it is to evaluate, test accuracy of 87.3 was observed.  \n",
        "\n",
        "Upon loading the weights of best validation accuracy of 88.02%, the test accuracy observed was 88.03%.\n",
        "\n",
        "Logs are attached for the two runs, the first one that lasted for 12 epochs and the other that went on for rest of the 38 epochs.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e9c025ba-7492-4823-a25b-92ef49009fe7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526459423664,
          "user_tz": -330,
          "elapsed": 4015,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\r\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\r\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.3)\r\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.7.1)\r\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2yDRWTPFq7st",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e7c10cc-5b8a-4574-a418-5865a3078e0c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526459425500,
          "user_tz": -330,
          "elapsed": 1533,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "from keras.callbacks import ModelCheckpoint,CSVLogger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 12\n",
        "num_filter = 24\n",
        "compression = 0.5\n",
        "dropout_rate = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "Conv2D_7x1 = Conv2D(num_filter,(7,1),use_bias=False,padding='same')(input)\n",
        "Conv2D_1x7 = Conv2D(num_filter,(1,7),use_bias=False,padding='same')(Conv2D_7x1)\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(Conv2D_1x7)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STBbUJZflhi4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Saving the weights during the training"
      ]
    },
    {
      "metadata": {
        "id": "O5keCtUEqoy7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "trainlog = CSVLogger(\"training.log\")\n",
        "callbacks_list = [checkpoint,trainlog]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P3MJ35igqpDW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 8194
        },
        "outputId": "a4b99387-e045-4384-d998-c2a1a9530dda",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526459469318,
          "user_tz": -330,
          "elapsed": 967,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 24)   504         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 24)   4032        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 24)   5184        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 12)   2592        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 36)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 12)   3888        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 12)   5184        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 60)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 12)   6480        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 72)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 12)   7776        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 84)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 12)   9072        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 96)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 12)   10368       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 108)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 12)   11664       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 120)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 12)   12960       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 132)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 132)  528         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 132)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 12)   14256       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 144)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 144)  576         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 144)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 12)   15552       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 156)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 156)  624         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 156)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 12)   16848       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 168)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 168)  672         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 168)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 12)   2016        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 12)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 12)   1296        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 24)   0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 24)   96          concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 24)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 12)   2592        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 36)   0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 36)   144         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 36)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 12)   3888        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 48)   0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 48)   192         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 48)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 12)   5184        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 60)   0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 60)   240         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 60)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 12)   6480        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 72)   0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 72)   288         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 72)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 12)   7776        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 84)   0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 84)   336         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 84)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 12)   9072        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 96)   0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 96)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 12)   10368       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 108)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 108)  432         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 108)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 12)   11664       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 120)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 120)  480         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 120)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 12)   12960       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 132)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 132)  528         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 132)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 12)   14256       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 144)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 144)  576         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 144)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 12)   15552       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 156)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 156)  624         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 156)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 12)   1872        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 12)     0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 12)     1296        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 24)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 24)     96          concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 24)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 12)     2592        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 36)     0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 36)     144         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 36)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 12)     3888        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 48)     0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 48)     192         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 48)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 12)     5184        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 60)     0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 60)     240         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 60)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 12)     6480        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 72)     0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 72)     288         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 72)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 12)     7776        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 84)     0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 84)     336         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 84)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 12)     9072        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 96)     0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 96)     384         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 96)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 12)     10368       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 108)    0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 108)    432         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 108)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 12)     11664       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 120)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 120)    480         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 120)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 12)     12960       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 132)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 132)    528         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 132)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 12)     14256       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 144)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 144)    576         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 144)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 12)     15552       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 156)    0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 156)    624         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 156)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 12)     1872        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 12)     0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 12)     1296        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 4, 4, 24)     0           average_pooling2d_3[0][0]        \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 24)     96          concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 24)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 12)     2592        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4, 36)     0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 36)     144         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 36)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 12)     3888        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 48)     0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 48)     192         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 48)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 12)     5184        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 60)     0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 60)     240         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 60)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 12)     6480        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 72)     0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 72)     288         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 72)     0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 12)     7776        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 84)     0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 84)     336         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 84)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 12)     9072        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 96)     0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 96)     384         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 96)     0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 12)     10368       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 108)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 108)    432         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 108)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 12)     11664       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 120)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 120)    480         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 120)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 12)     12960       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 132)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 132)    528         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 132)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 4, 4, 12)     14256       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 144)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 144)    576         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 144)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 12)     15552       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 4, 4, 156)    0           concatenate_47[0][0]             \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 4, 4, 156)    624         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 4, 4, 156)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 2, 2, 156)    0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 624)          0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           6250        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 459,730\n",
            "Trainable params: 450,682\n",
            "Non-trainable params: 9,048\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YQEi-NJlt2B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding data augmentation"
      ]
    },
    {
      "metadata": {
        "id": "jOPMqRCmlsyZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_gen = ImageDataGenerator( \n",
        "                          rotation_range=10, \n",
        "                          width_shift_range=0.2, \n",
        "                          height_shift_range=0.2, \n",
        "                          zoom_range=0.25,\n",
        "                          horizontal_flip=True)\n",
        "\n",
        "validation_data_gen = ImageDataGenerator()\n",
        "train_generator = train_data_gen.flow(x_train, y_train, batch_size=batch_size)\n",
        "validation_generator = validation_data_gen.flow(x_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "63b25119-fe43-49c8-82f5-9f1802b9e28f"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch=train_generator.n//batch_size, \n",
        "                    epochs=50, \n",
        "                    callbacks=callbacks_list, \n",
        "                    verbose =1,\n",
        "                    validation_data=validation_generator, \n",
        "                    validation_steps=validation_generator.n//batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "781/781 [==============================] - 313s 401ms/step - loss: 1.7094 - acc: 0.3701 - val_loss: 1.6283 - val_acc: 0.4266\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.42658, saving model to weights.best.hdf5\n",
            "Epoch 2/50\n",
            " 88/781 [==>...........................] - ETA: 4:12 - loss: 1.5060 - acc: 0.4547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 300s 385ms/step - loss: 1.3660 - acc: 0.5082 - val_loss: 1.1774 - val_acc: 0.5698\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.42658 to 0.56981, saving model to weights.best.hdf5\n",
            "Epoch 3/50\n",
            "141/781 [====>.........................] - ETA: 3:52 - loss: 1.2312 - acc: 0.5541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 301s 386ms/step - loss: 1.1506 - acc: 0.5892 - val_loss: 1.1494 - val_acc: 0.6010\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.56981 to 0.60096, saving model to weights.best.hdf5\n",
            "Epoch 4/50\n",
            "155/781 [====>.........................] - ETA: 3:48 - loss: 1.0584 - acc: 0.6218"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 301s 385ms/step - loss: 1.0159 - acc: 0.6407 - val_loss: 1.2112 - val_acc: 0.6072\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.60096 to 0.60717, saving model to weights.best.hdf5\n",
            "Epoch 5/50\n",
            "159/781 [=====>........................] - ETA: 3:45 - loss: 0.9632 - acc: 0.6567"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 302s 387ms/step - loss: 0.9251 - acc: 0.6738 - val_loss: 0.9075 - val_acc: 0.6865\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.60717 to 0.68650, saving model to weights.best.hdf5\n",
            "Epoch 6/50\n",
            "160/781 [=====>........................] - ETA: 3:46 - loss: 0.8601 - acc: 0.6971"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 387ms/step - loss: 0.8399 - acc: 0.7050 - val_loss: 1.0532 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.68650\n",
            "Epoch 7/50\n",
            "184/781 [======>.......................] - ETA: 3:38 - loss: 0.8046 - acc: 0.7191"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 302s 387ms/step - loss: 0.7880 - acc: 0.7237 - val_loss: 1.4402 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.68650\n",
            "Epoch 8/50\n",
            "192/781 [======>.......................] - ETA: 3:35 - loss: 0.7414 - acc: 0.7387"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 302s 386ms/step - loss: 0.7430 - acc: 0.7408 - val_loss: 0.8716 - val_acc: 0.7021\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.68650 to 0.70212, saving model to weights.best.hdf5\n",
            "Epoch 9/50\n",
            "169/781 [=====>........................] - ETA: 3:41 - loss: 0.6947 - acc: 0.7581"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 300s 384ms/step - loss: 0.6981 - acc: 0.7552 - val_loss: 0.8115 - val_acc: 0.7276\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.70212 to 0.72756, saving model to weights.best.hdf5\n",
            "Epoch 10/50\n",
            "162/781 [=====>........................] - ETA: 3:44 - loss: 0.6706 - acc: 0.7686"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 301s 385ms/step - loss: 0.6657 - acc: 0.7674 - val_loss: 1.1016 - val_acc: 0.6695\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.72756\n",
            "Epoch 11/50\n",
            "184/781 [======>.......................] - ETA: 3:36 - loss: 0.6534 - acc: 0.7751"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 300s 384ms/step - loss: 0.6445 - acc: 0.7764 - val_loss: 0.9273 - val_acc: 0.7095\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.72756\n",
            "Epoch 12/50\n",
            "191/781 [======>.......................] - ETA: 3:33 - loss: 0.6054 - acc: 0.7917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.6157 - acc: 0.7846 - val_loss: 0.6648 - val_acc: 0.7778\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.72756 to 0.77784, saving model to weights.best.hdf5\n",
            "Epoch 13/50\n",
            "168/781 [=====>........................] - ETA: 3:46 - loss: 0.6059 - acc: 0.7880"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "378/781 [=============>................] - ETA: 2:28 - loss: 0.5937 - acc: 0.7923"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G8XYEoxDqgyG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training Log for Epoch 1 to 12  \n",
        "#### epoch,acc,loss,val_acc,val_loss  \n",
        "  \n",
        "\n",
        "0,0.3701537968599808,1.709243738777322,0.42658253205128205,1.6283374016101544\n",
        "1,0.5080903556552387,1.3661691263599756,0.5698116987179487,1.177447960162774\n",
        "2,0.5891340916372957,1.1504799168830269,0.6009615384615384,1.1494317127343936\n",
        "3,0.6407000961230375,1.0158001427007233,0.6071714743589743,1.2112317566688244\n",
        "4,0.6736622877282922,0.9254216284218678,0.6864983974358975,0.9074608779106385\n",
        "5,0.7051826337712271,0.8393835356433359,0.6469350961538461,1.0532327664968295\n",
        "6,0.7236462672220442,0.7880550019445423,0.5992588141025641,1.440164443009939\n",
        "7,0.7409083627042614,0.7425034802069231,0.7021233974358975,0.8715929431028855\n",
        "8,0.7550865107337392,0.6983746800694624,0.7275641025641025,0.8114863913028668\n",
        "9,0.7675024030759372,0.6656979080271698,0.6694711538461539,1.1016396081600435\n",
        "10,0.7764138096763857,0.6441716925527223,0.7095352564102564,0.9272776737045019\n",
        "**11,0.7846443447612944,0.6156081741568905,0.7778445512820513,0.6647945105647429**"
      ]
    },
    {
      "metadata": {
        "id": "G3JGfsrqE4Dt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Training was interrupted due to runtime termination after epoch 12. Using saved weights to resume training for another 38 epochs"
      ]
    },
    {
      "metadata": {
        "id": "W2bwTY1VFQ6y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d75e922-9b27-47ea-840c-048ee5c868ca",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526459617089,
          "user_tz": -330,
          "elapsed": 1951,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  training.log  weights.best.hdf5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I2QlwicKFVy-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"weights.best.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30qYQexKFux3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2618
        },
        "outputId": "23220e5b-6663-42bb-c9d4-0cd2e5ec59c8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526471294459,
          "user_tz": -330,
          "elapsed": 11559330,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch=train_generator.n//batch_size, \n",
        "                    epochs=38, \n",
        "                    callbacks=callbacks_list, \n",
        "                    verbose =1,\n",
        "                    validation_data=validation_generator, \n",
        "                    validation_steps=validation_generator.n//batch_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/38\n",
            "781/781 [==============================] - 310s 397ms/step - loss: 0.5094 - acc: 0.8241 - val_loss: 0.7401 - val_acc: 0.7664\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.76643, saving model to weights.best.hdf5\n",
            "Epoch 2/38\n",
            " 88/781 [==>...........................] - ETA: 4:14 - loss: 0.4705 - acc: 0.8386"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 304s 389ms/step - loss: 0.4986 - acc: 0.8278 - val_loss: 0.6024 - val_acc: 0.7916\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.76643 to 0.79157, saving model to weights.best.hdf5\n",
            "Epoch 3/38\n",
            "141/781 [====>.........................] - ETA: 3:55 - loss: 0.4932 - acc: 0.8267"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 304s 389ms/step - loss: 0.4857 - acc: 0.8293 - val_loss: 0.6767 - val_acc: 0.7825\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79157\n",
            "Epoch 4/38\n",
            "179/781 [=====>........................] - ETA: 3:41 - loss: 0.4606 - acc: 0.8413"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4744 - acc: 0.8339 - val_loss: 0.6572 - val_acc: 0.7882\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79157\n",
            "Epoch 5/38\n",
            "190/781 [======>.......................] - ETA: 3:37 - loss: 0.4588 - acc: 0.8431"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4634 - acc: 0.8389 - val_loss: 0.6838 - val_acc: 0.7889\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.79157\n",
            "Epoch 6/38\n",
            "194/781 [======>.......................] - ETA: 3:34 - loss: 0.4657 - acc: 0.8392"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4574 - acc: 0.8409 - val_loss: 0.8514 - val_acc: 0.7519\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79157\n",
            "Epoch 7/38\n",
            "195/781 [======>.......................] - ETA: 3:34 - loss: 0.4414 - acc: 0.8461"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4461 - acc: 0.8462 - val_loss: 0.5137 - val_acc: 0.8267\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79157 to 0.82672, saving model to weights.best.hdf5\n",
            "Epoch 8/38\n",
            "169/781 [=====>........................] - ETA: 3:45 - loss: 0.4368 - acc: 0.8494"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4364 - acc: 0.8500 - val_loss: 0.5981 - val_acc: 0.8056\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.82672\n",
            "Epoch 9/38\n",
            "187/781 [======>.......................] - ETA: 3:36 - loss: 0.4382 - acc: 0.8492"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 302s 387ms/step - loss: 0.4281 - acc: 0.8520 - val_loss: 0.4863 - val_acc: 0.8422\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82672 to 0.84225, saving model to weights.best.hdf5\n",
            "Epoch 10/38\n",
            "167/781 [=====>........................] - ETA: 3:44 - loss: 0.4136 - acc: 0.8559"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4226 - acc: 0.8520 - val_loss: 0.5700 - val_acc: 0.8168\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.84225\n",
            "Epoch 11/38\n",
            "186/781 [======>.......................] - ETA: 3:38 - loss: 0.4111 - acc: 0.8586"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4137 - acc: 0.8579 - val_loss: 0.5826 - val_acc: 0.8157\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.84225\n",
            "Epoch 12/38\n",
            "192/781 [======>.......................] - ETA: 3:35 - loss: 0.4087 - acc: 0.8577"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4073 - acc: 0.8576 - val_loss: 0.6478 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.84225\n",
            "Epoch 13/38\n",
            "193/781 [======>.......................] - ETA: 3:35 - loss: 0.4149 - acc: 0.8564"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.4048 - acc: 0.8577 - val_loss: 0.5269 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.84225\n",
            "Epoch 14/38\n",
            "194/781 [======>.......................] - ETA: 3:33 - loss: 0.3938 - acc: 0.8613"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 302s 387ms/step - loss: 0.3938 - acc: 0.8624 - val_loss: 0.4316 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.84225 to 0.85807, saving model to weights.best.hdf5\n",
            "Epoch 15/38\n",
            "169/781 [=====>........................] - ETA: 3:44 - loss: 0.3930 - acc: 0.8665"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 304s 389ms/step - loss: 0.3909 - acc: 0.8652 - val_loss: 0.6256 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85807\n",
            "Epoch 16/38\n",
            "186/781 [======>.......................] - ETA: 3:38 - loss: 0.3689 - acc: 0.8703"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 304s 389ms/step - loss: 0.3808 - acc: 0.8661 - val_loss: 0.4473 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.85807\n",
            "Epoch 17/38\n",
            "192/781 [======>.......................] - ETA: 3:35 - loss: 0.3697 - acc: 0.8717"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 304s 389ms/step - loss: 0.3768 - acc: 0.8691 - val_loss: 0.4531 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.85807\n",
            "Epoch 18/38\n",
            "193/781 [======>.......................] - ETA: 3:34 - loss: 0.3688 - acc: 0.8661"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3740 - acc: 0.8681 - val_loss: 0.4940 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.85807\n",
            "Epoch 19/38\n",
            "194/781 [======>.......................] - ETA: 3:34 - loss: 0.3559 - acc: 0.8740"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3685 - acc: 0.8705 - val_loss: 0.6134 - val_acc: 0.8127\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.85807\n",
            "Epoch 20/38\n",
            "194/781 [======>.......................] - ETA: 3:36 - loss: 0.3471 - acc: 0.8806"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3591 - acc: 0.8748 - val_loss: 0.3953 - val_acc: 0.8676\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.85807 to 0.86759, saving model to weights.best.hdf5\n",
            "Epoch 21/38\n",
            "169/781 [=====>........................] - ETA: 3:43 - loss: 0.3465 - acc: 0.8805"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3554 - acc: 0.8770 - val_loss: 0.4855 - val_acc: 0.8435\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.86759\n",
            "Epoch 22/38\n",
            "186/781 [======>.......................] - ETA: 3:37 - loss: 0.3507 - acc: 0.8759"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3552 - acc: 0.8757 - val_loss: 0.5073 - val_acc: 0.8421\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.86759\n",
            "Epoch 23/38\n",
            "192/781 [======>.......................] - ETA: 3:35 - loss: 0.3508 - acc: 0.8810"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3491 - acc: 0.8800 - val_loss: 0.4805 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.86759\n",
            "Epoch 24/38\n",
            "193/781 [======>.......................] - ETA: 3:34 - loss: 0.3465 - acc: 0.8796"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 302s 387ms/step - loss: 0.3490 - acc: 0.8791 - val_loss: 0.4673 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.86759\n",
            "Epoch 25/38\n",
            "194/781 [======>.......................] - ETA: 3:35 - loss: 0.3405 - acc: 0.8801"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3380 - acc: 0.8824 - val_loss: 0.3887 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.86759 to 0.87440, saving model to weights.best.hdf5\n",
            "Epoch 26/38\n",
            "169/781 [=====>........................] - ETA: 3:44 - loss: 0.3339 - acc: 0.8828"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 304s 389ms/step - loss: 0.3363 - acc: 0.8820 - val_loss: 0.4916 - val_acc: 0.8433\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.87440\n",
            "Epoch 27/38\n",
            "186/781 [======>.......................] - ETA: 3:37 - loss: 0.3377 - acc: 0.8849"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3302 - acc: 0.8857 - val_loss: 0.4003 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.87440\n",
            "Epoch 28/38\n",
            "192/781 [======>.......................] - ETA: 3:35 - loss: 0.3290 - acc: 0.8832"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3246 - acc: 0.8871 - val_loss: 0.4943 - val_acc: 0.8495\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.87440\n",
            "Epoch 29/38\n",
            "193/781 [======>.......................] - ETA: 3:35 - loss: 0.3239 - acc: 0.8871"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3229 - acc: 0.8872 - val_loss: 0.4717 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.87440\n",
            "Epoch 30/38\n",
            "194/781 [======>.......................] - ETA: 3:34 - loss: 0.3277 - acc: 0.8865"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3238 - acc: 0.8869 - val_loss: 0.4999 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.87440\n",
            "Epoch 31/38\n",
            "194/781 [======>.......................] - ETA: 3:34 - loss: 0.3204 - acc: 0.8892"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3215 - acc: 0.8891 - val_loss: 0.4840 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.87440\n",
            "Epoch 32/38\n",
            "194/781 [======>.......................] - ETA: 3:35 - loss: 0.3150 - acc: 0.8885"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3149 - acc: 0.8897 - val_loss: 0.4569 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.87440\n",
            "Epoch 33/38\n",
            "194/781 [======>.......................] - ETA: 3:35 - loss: 0.3086 - acc: 0.8926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3106 - acc: 0.8925 - val_loss: 0.4501 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.87440\n",
            "Epoch 34/38\n",
            "194/781 [======>.......................] - ETA: 3:33 - loss: 0.3044 - acc: 0.8912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 302s 387ms/step - loss: 0.3080 - acc: 0.8908 - val_loss: 0.5773 - val_acc: 0.8284\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.87440\n",
            "Epoch 35/38\n",
            "194/781 [======>.......................] - ETA: 3:34 - loss: 0.2951 - acc: 0.8963"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.2995 - acc: 0.8955 - val_loss: 0.3758 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.87440 to 0.88021, saving model to weights.best.hdf5\n",
            "Epoch 36/38\n",
            "169/781 [=====>........................] - ETA: 3:43 - loss: 0.3051 - acc: 0.8940"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3027 - acc: 0.8937 - val_loss: 0.4311 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.88021\n",
            "Epoch 37/38\n",
            "186/781 [======>.......................] - ETA: 3:38 - loss: 0.3000 - acc: 0.8939"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.3022 - acc: 0.8951 - val_loss: 0.4354 - val_acc: 0.8632\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.88021\n",
            "Epoch 38/38\n",
            "192/781 [======>.......................] - ETA: 3:35 - loss: 0.2965 - acc: 0.8971"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 303s 388ms/step - loss: 0.2965 - acc: 0.8962 - val_loss: 0.4048 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.88021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efed38f8cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "ALG9R8wL3VUQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training Log for Epoch 13 to 50   \n",
        "\n",
        "#### epoch,acc,loss,val_acc,val_loss    \n",
        "\n",
        "\n",
        "0,0.8242550464594681,0.5087492304213419,0.766426282051282,0.7401369857864503\n",
        "1,0.8277995834668376,0.49855676676286637,0.7915665064102564,0.6024200304960593\n",
        "2,0.8292614546619673,0.4857004265474303,0.7824519230769231,0.6766831647509184\n",
        "3,0.8340676065363666,0.4739943714869095,0.7881610576923077,0.6571524939857997\n",
        "4,0.8388937840435757,0.46314855662342524,0.7888621794871795,0.683842563476318\n",
        "5,0.8409564242230054,0.4573263793333873,0.7519030448717948,0.8514463431560076\n",
        "6,0.8462031400192246,0.44579366845452073,0.8267227564102564,0.5136595924313252\n",
        "7,0.849927907721884,0.43644575874456343,0.8055889423076923,0.5981472298885003\n",
        "8,0.8518904197372636,0.4282795712184692,0.8422475961538461,0.486338974096072\n",
        "9,0.8518904197372636,0.4228127078439364,0.8168068910256411,0.569960644038824\n",
        "10,0.8578380326818328,0.4138376099564486,0.8157051282051282,0.5825908646369592\n",
        "11,0.8576578019865427,0.40703976064567116,0.8023838141025641,0.6478387875816761\n",
        "12,0.8577779557834028,0.4045132199795878,0.8293269230769231,0.5268991558979719\n",
        "13,0.862483979493752,0.3937728417985373,0.8580729166666666,0.43161654902192265\n",
        "14,0.8651674142902915,0.3908265250991912,0.8051883012820513,0.6256343785386819\n",
        "15,0.8663088753604614,0.3804098418682518,0.8497596153846154,0.44730619427103263\n",
        "16,0.8691324895866709,0.3765718101958593,0.8531650641025641,0.4531276652064079\n",
        "17,0.8681111823133612,0.37401725701780053,0.83984375,0.49404423425977045\n",
        "18,0.8706143864146108,0.36838437114072053,0.8127003205128205,0.6134260868032774\n",
        "19,0.87487984620314,0.3588835015983698,0.8675881410256411,0.39528671929087394\n",
        "20,0.8769224607497597,0.3555311407322152,0.8435496794871795,0.48546443573939496\n",
        "21,0.8756608458827299,0.35530852686610215,0.8421474358974359,0.5073332617489191\n",
        "22,0.8800016005121639,0.34906400301316026,0.8456530448717948,0.48053889950880635\n",
        "23,0.8790691148171905,0.3490593365517238,0.8486578525641025,0.4672662219366966\n",
        "**24,0.8826097404677988,0.3376938025850548,0.8743990384615384,0.38871548630488223**\n",
        "25,0.8821090996475489,0.3360536029345712,0.8433493589743589,0.49158675987751055\n",
        "26,0.8856336110221082,0.33037694730043643,0.8685897435897436,0.4002963486008155\n",
        "27,0.8871155078500481,0.3245861655395408,0.8494591346153846,0.49426455604724395\n",
        "28,0.8870554309516181,0.32317237779426483,0.8536658653846154,0.47174655741606003\n",
        "29,0.8867550464594681,0.32392090227179177,0.8385416666666666,0.49987101822327346\n",
        "30,0.8890379685998078,0.3214647053564561,0.8475560897435898,0.4839865692341939\n",
        "31,0.8896988144825376,0.31493389705785074,0.8500600961538461,0.45689149162708187\n",
        "32,0.8924223005446972,0.3106276677400399,0.8586738782051282,0.4500655401020478\n",
        "33,0.8909404037167574,0.3076592045921196,0.8284254807692307,0.5773284009251839\n",
        "**34,0.8954461710990067,0.2996342634971384,0.8802083333333334,0.37583819251412**\n",
        "35,0.8936238385132971,0.3028916935652771,0.8655849358974359,0.43110579897004825\n",
        "36,0.8950456584428068,0.30244991495293405,0.8631810897435898,0.43544238557418186\n",
        "37,0.8962467989756722,0.2964690421611338,0.8727964743589743,0.4047875019411246"
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b49ef2d7-d199-49b7-f547-a4f6a37fe68d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526471412305,
          "user_tz": -330,
          "elapsed": 23115,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 22s 2ms/step\n",
            "Test loss: 0.4042066404819489\n",
            "Test accuracy: 0.873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3daca105-0515-4c56-c7f6-8279829b2f7d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526471421170,
          "user_tz": -330,
          "elapsed": 1741,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QgrjQ6OKqgy1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the saved weights to evaluate"
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "044660c7-11b3-429e-a748-7fe5655455aa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526471487592,
          "user_tz": -330,
          "elapsed": 56860,
          "user": {
            "displayName": "Avinash K",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102947600961494059759"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"weights.best.hdf5\")\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 25s 2ms/step\n",
            "Test loss: 0.3754211556315422\n",
            "Test accuracy: 0.8803\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}